{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mmdet.ipynb","provenance":[{"file_id":"1gM6-lvyt6GLNRdLTqdJcUpOkczTr2Uld","timestamp":1639406105238}],"collapsed_sections":["wufItooT8f0N"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 패키지 다운로드 & 버전 확인"],"metadata":{"id":"s2fWVEjHNcXX"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"z0NAs7gwTP7I"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAMRV1auulY5","executionInfo":{"status":"aborted","timestamp":1639784772763,"user_tz":-540,"elapsed":4,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"source":["!nvcc -V\n","!echo\n","!gcc --version\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2Q79UVGdqb5"},"source":["!git clone https://github.com/SwinTransformer/Swin-Transformer-Object-Detection.git\n","!pip install -r /content/Swin-Transformer-Object-Detection/requirements.txt\n","!pip install openmim\n","!mim install mmdet\n","!pip install tqdm\n","\n","!git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n","%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 다운로드 & 오류데이터 수정"],"metadata":{"id":"9X0AgaAJNYRI"}},{"cell_type":"code","metadata":{"id":"cWOqK47Fy-Ig"},"source":["!unzip '/content/drive/MyDrive/input/ocr_ancient.zip' -d /content/data\n","# !unzip '/content/drive/MyDrive/input/train.zip' -d /content/data\n","# !unzip '/content/drive/MyDrive/input/valid.zip' -d /content/data"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/input/train.json /content/data/train.json\n","!cp /content/drive/MyDrive/input/valid.json /content/data/valid.json"],"metadata":{"id":"dRYhdBVt1gt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xx7LfTu1Q9Qq"},"source":["# 목판본_043_언해류_대학언해_01\n","# 목판본_043_언해류_대학언해1_01\n","# 필사본_104_문학류_대명영렬전2_01\n","# 필사본_104_문학류_대병영렬전2_01\n","# 필사본_105_문학류_대명영렬전3_01\n","# 필사본_105_문학류_대병영렬전3_01\n","import os\n","from glob import glob\n","json_list = glob(os.path.join('/content/data/이미지데이터','*')) # derectory\n","for i in json_list:\n","    tmp_list = glob(os.path.join(i,'*'))\n","    for j in tmp_list: # image파일\n","\n","        if j.split('/')[-1][:-8] != i.split('/')[-1]:\n","            dir_name = i.split('/')[-1]\n","            img_number = j.split('/')[-1][-8:]\n","            os.rename(j, '/content/data/이미지데이터/'+dir_name+'/'+dir_name+img_number)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 전처리"],"metadata":{"id":"IA1QUDreNQOY"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import seaborn as sns\n","import random\n","\n","from collections import defaultdict, Counter\n","import json\n","from glob import glob\n","import pycocotools"],"metadata":{"id":"dS0X3FAxap1Q","executionInfo":{"status":"ok","timestamp":1639784784912,"user_tz":-540,"elapsed":1007,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## seg없이 데이터만들기"],"metadata":{"id":"wufItooT8f0N"}},{"cell_type":"code","source":["def make_dataset(mode='train'):\n","\n","    os.makedirs(f'/content/data/{mode}', exist_ok=True)\n","    dir_list = glob('/content/data/라벨링데이터/*')\n","\n","    count = 0\n","\n","    image_idx = 0\n","    annotation_idx = 0\n","\n","    images = [] # images.append({'id':image_idx, 'file_name': jf_name+'/'+jf_name+file_name[-4:]+'.png','width':d['Image_Width'], 'height':d['Image_Height']})\n","    annotations = [] # annotations.append({'id':annotations_idx, 'image_id':image_idx, 'category_id':0,\\\n","                    # 'bbox':(x,y,w,h), 'area':w*h, 'ignore':0,'iscrowd':0,'segmentation':[]})\n","    for idx, i in tqdm(enumerate(dir_list)): # directory\n","        print(idx, i)\n","        dir_name = i.split('/')[-1]\n","        json_list = glob(os.path.join(i, '*')) # json파일\n","        if mode == 'train': ################################################# train, valid 비율설정\n","            iter = json_list[:int(len(json_list)*0.5)]\n","        else:\n","            iter = json_list[int(len(json_list)*0.8):]\n","        for j in iter:\n","            with open(j, 'r', encoding='utf-8-sig') as jfile:\n","                d = json.load(jfile)\n","                image_name = d['Image_filename']\n","                image_num = image_name[-4:]\n","                if d['Image_Char_no'] > 400:\n","                    continue\n","                \n","                image = plt.imread(i.replace('라벨링데이터','이미지데이터')+'/'+dir_name+image_num+'.png') # h, w, c\n","\n","    #             image = np.zeros((int(d['Image_Height']), int(d['Image_Width']), 3), dtype=int)\n","                h,w,c = image.shape\n","\n","                ### ----------------- Min, Max 계산 ----------------- ###\n","                min_y, max_y, min_x, max_x = 1e9, 0, 1e9, 0\n","                for k in d['Text_Coord']:\n","                    bbox = k['bbox'] # x,y,w,h\n","                    min_y, max_y, min_x, max_x = min(min_y, bbox[1]), max(max_y,bbox[1]+bbox[3]),\\\n","                                                min(min_x, bbox[0]), max(max_x,bbox[0]+bbox[2])\n","                # 자를 지점 결과\n","                mini_y, maxi_y, mini_x, maxi_x = max(0,min_y-32), min(h,max_y+32), max(0,min_x-32), min(w, max_x+32)\n","                \n","                ### ----------------- 글 주변만 자른 이미지 ----------------- ###\n","                result = image[mini_y:maxi_y, mini_x:maxi_x,:]\n","                h_, w_, c_ = result.shape\n","                \n","                ### ----------------- 가운데를 자르기 전 빈 공간이 있는지 체크 ----------------- ###\n","                width_check = np.array([0]*w_)\n","\n","                for k in d['Text_Coord']:\n","                    bbox = k['bbox']\n","                    annotate = k['annotate']\n","                    # pp = image[bbox[1]-mini_y:bbox[1]-mini_y+bbox[3],bbox[0]-mini_x:bbox[0]-mini_x+bbox[2],:]\n","                    width_check[bbox[0]-mini_x:bbox[0]-mini_x+bbox[2]] += 1\n","                    # rect = patches.Rectangle((bbox[0]-mini_x,bbox[1]-mini_y),bbox[2],bbox[3], linewidth=3, edgecolor='r', facecolor='none')\n","                    # ax.add_patch(rect)\n","                plt.show()\n","                \n","                ### ----------------- 빈 공간이 있으면 이미지 분할 ----------------- ###\n","                cutting = None\n","                start = None # 빈공간의 처음지점\n","                end = None # 빈공간의 마지막 지점 --> 치우치지 않게 자르기 위함\n","                flag = False\n","                if h_/w_ < 1.0:\n","                    for n in range(10, -25,-1):\n","                        if width_check[w_//2 + n] == 0 and flag == False:\n","                            start = w_//2 + n\n","                            end = w_//2 + n\n","                            flag = True\n","                        elif width_check[w_//2 + n] == 0 and flag == True:\n","                            end = w_//2 + n\n","                        elif width_check[w_//2 + n] != 0 and flag == True:\n","                            end = w_//2 + n\n","                            break\n","                        else:\n","                            continue\n","                    if start is None or end is None: # 가로가 긴데 못자르면 패스\n","                        continue\n","                        \n","                    cutting = (start+end)//2\n","                    \n","                    left_coord = []\n","                    right_coord = []\n","                    \n","                    for k in d['Text_Coord']:\n","                        bbox = k['bbox']\n","                        bbox_ = [bbox[0]-mini_x,bbox[1]-mini_y,bbox[2],bbox[3]] # 원래 bbox에서 여백제거한만큼 이동\n","                        if bbox_[0] > cutting:\n","                            bbox_[0] -= cutting\n","                            right_coord.append(bbox_)\n","                        else:\n","                            left_coord.append(bbox_)\n","                    \n","                    image_left = result[:,:cutting,:]\n","                    image_right = result[:,cutting:,:]\n","                    \n","                    h_left, w_left, _ = image_left.shape\n","                    h_right, w_right, _ = image_right.shape\n","                    if 2 > h_left / w_left >= 1: # 자른 후 세로가 길어야 저장\n","                        plt.imsave(f'/content/data/{mode}/{image_idx:05d}.png', image_left)\n","                        images.append({'id':image_idx, 'file_name': f'{image_idx:05d}.png',\\\n","                                    'width':w_left, 'height':h_left})\n","                        for ann in left_coord:\n","                            if 0 > ann[0] or ann[0]+ann[2] > w_left or 0 > ann[1] or ann[1]+ann[3] > h_left:\n","                                continue\n","                            annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                                    'bbox':(ann[0],ann[1],ann[2],ann[3]), 'area':ann[2]*ann[3], 'ignore':0,'iscrowd':0,'segmentation':[]})\n","                            annotation_idx += 1\n","                        image_idx += 1\n","                    if 2 > h_right / w_right >= 1:\n","                        plt.imsave(f'/content/data/{mode}/{image_idx:05d}.png', image_right)\n","                        images.append({'id':image_idx, 'file_name': f'{image_idx:05d}.png',\\\n","                                    'width':w_right, 'height':h_right})\n","                        for ann in right_coord:\n","                            if 0 > ann[0] or ann[0]+ann[2] > w_left or 0 > ann[1] or ann[1]+ann[3] > h_left:\n","                                continue\n","                            annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                                    'bbox':(ann[0],ann[1],ann[2],ann[3]), 'area':ann[2]*ann[3], 'ignore':0,'iscrowd':0,'segmentation':[]})\n","                            annotation_idx += 1\n","\n","                        image_idx += 1\n","                        \n","                    \n","                else: # 세로가 길면\n","                    if h_/w_ > 2 or d['Image_Char_no'] > 200:\n","                        count += 1\n","                        continue\n","                    plt.imsave(f'/content/data/{mode}/{image_idx:05d}.png', result)\n","                    # fig, ax = plt.subplots(figsize=(8,8))\n","                    # ax.imshow(result)\n","                    images.append({'id':image_idx, 'file_name': f'{image_idx:05d}.png',\\\n","                                'width':w_, 'height':h_})\n","                    for ann in d['Text_Coord']:\n","                        x,y,w,h = ann['bbox'][:4]\n","                        if 0 > x or x+w > w_ or 0 > y or y+h > h_:\n","                            continue\n","                        annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                                'bbox':(x-mini_x,y-mini_y,w,h), 'area':w*h, 'ignore':0,'iscrowd':0,'segmentation':[]})\n","                        rect = patches.Rectangle((x-mini_x,y-mini_y),w,h, linewidth=3, edgecolor='r', facecolor='none')\n","                        # ax.add_patch(rect)\n","                        annotation_idx += 1\n","                    image_idx += 1\n","                    # plt.show()\n","    return images, annotations"],"metadata":{"id":"xDz2CHs8NrN4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## seg 잇이"],"metadata":{"id":"jcOWE67T8qku"}},{"cell_type":"code","source":["!rm -rf /content/data/train\n","!rm -rf /content/data/valid\n","!rm -rf /content/data/train.json\n","!rm -rf /content/data/valid.json"],"metadata":{"id":"0iDq0zRoCDcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decide_min_max(coordinates : dict, h, w):\n","    min_y, max_y, min_x, max_x = 1e9, 0, 1e9, 0\n","\n","    for i in coordinates:\n","        bbox = i['bbox']\n","        min_y, max_y, min_x, max_x = min(min_y, bbox[1]), max(max_y,bbox[1]+bbox[3]),\\\n","                                    min(min_x, bbox[0]), max(max_x,bbox[0]+bbox[2])\n","    mini_y, maxi_y, mini_x, maxi_x = max(0,min_y-32), min(h,max_y+32), max(0,min_x-32), min(w, max_x+32)\n","    return mini_y, maxi_y, mini_x, maxi_x\n","\n","\n","def make_segmentation(x,y,w,h,image):\n","    \"\"\"bbox로부터 segmentation 추출\"\"\"\n","    base = np.zeros(image.shape[:2])\n","    # box = image[y:y+h,x:x+w,:]\n","    # rgb_distance = np.abs(box[:,:,0] - box[:,:,1]) + np.abs(box[:,:,1] - box[:,:,2]) + np.abs(box[:,:,2] - box[:,:,0])\n","    # rgb_mask = np.zeros((h,w))\n","    # for m in np.argwhere(rgb_distance < 0.7):\n","    #     rgb_mask[m[0], m[1]] = 1\n","    \n","    # box_gray = np.mean(box, axis=2)\n","    # mean_box = np.mean(box.flatten())\n","    # under_mean = np.argwhere(box_gray <= mean_box*0.9)\n","    # zero_arg = np.argwhere(box_gray <= np.min(box_gray.flatten())+0.01)\n","    # tmp_mask = np.zeros((h,w))\n","    # for m in under_mean:\n","    #     tmp_mask[m[0],m[1]] = 1\n","    # for m in zero_arg:\n","    #     tmp_mask[m[0],m[1]] = 1\n","    # total_mask = rgb_mask * tmp_mask\n","    # if np.sum(total_mask.flatten()) < 4:\n","    #     return None\n","    base[y:y+h, x:x+w] = total_mask\n","    base = np.asfortranarray(base).astype(np.uint8)\n","    seg = pycocotools.mask.encode(base)\n","    seg['counts'] = seg['counts'].decode('ascii')\n","    # seg = np.flip(np.argwhere(total_mask==1),axis=1) + [x,y]\n","    return seg\n","\n","def append_annotations(image,image_half,coords,annotations,image_idx,annotation_idx,seg_option,full):\n","    if image.shape[0]*image.shape[1] > 4000000:\n","        for ann in coords: ############################################### Annotation\n","            x,y,w,h = ann[:4]\n","            if full:\n","                x, y = x-full[0], y-full[1]\n","            if 0 > x or x+w > image.shape[1] or 0 > y or y+h > image.shape[0]:\n","                continue\n","            seg = None\n","            if seg_option:\n","                seg = make_segmentation(x//2,y//2,w//2,h//2,image_half)\n","                if seg is None:\n","                    continue\n","                annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                        'bbox':(x//2,y//2,w//2,h//2), 'area':w//2*h//2, 'ignore':0,'iscrowd':0,'segmentation':seg})\n","            else:\n","                annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                        'bbox':(x,y,w,h), 'area':w*h, 'ignore':0,'iscrowd':0,'segmentation':[]})\n","            annotation_idx += 1\n","    else:\n","        for ann in coords: \n","            x,y,w,h = ann[:4]\n","            if 0 > x or x+w > image.shape[1] or 0 > y or y+h > image.shape[0]:\n","                continue\n","            seg = None\n","            if seg_option:\n","                seg = make_segmentation(x,y,w,h,image)\n","                if seg is None:\n","                    continue\n","                annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                        'bbox':(x,y,w,h), 'area':w*h, 'ignore':0,'iscrowd':0,'segmentation':seg})\n","            else:\n","                annotations.append({'id':annotation_idx, 'image_id':image_idx, 'category_id':0,\\\n","                        'bbox':(x,y,w,h), 'area':w*h, 'ignore':0,'iscrowd':0,'segmentation':[]})\n","            annotation_idx += 1\n","    return annotations, annotation_idx\n","\n","def save_iamge(mode, image_idx, image, w, h):\n","    plt.imsave(f'/content/data/{mode}/{image_idx:05d}.png', image)\n","    images.append({'id':image_idx, 'file_name': f'{image_idx:05d}.png',\\\n","                'width':w//2, 'height':h//2})\n","    return images\n","\n","def decide_cutting_point(width_check, w_):\n","    cutting = None\n","    start, end = None, None # 빈공간의 처음지점, 빈공간의 마지막 지점 --> 치우치지 않게 자르기 위함\n","    flag = False\n","    for n in range(10, -25,-1):\n","        if width_check[w_//2 + n] == 0 and flag == False:\n","            start = w_//2 + n\n","            end = w_//2 + n\n","            flag = True\n","        elif width_check[w_//2 + n] == 0 and flag == True:\n","            end = w_//2 + n\n","        elif width_check[w_//2 + n] != 0 and flag == True:\n","            break\n","        else:\n","            continue\n","    if start is None: # 가로가 긴데 못자르면 패스\n","        cutting = None\n","    else:\n","        cutting = (start+end)//2\n","    return cutting"],"metadata":{"id":"_ezjjyWYAPwW","executionInfo":{"status":"ok","timestamp":1639786853157,"user_tz":-540,"elapsed":252,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def make_dataset(mode='train', seg_option=False):\n","    os.makedirs(f'/content/data/{mode}', exist_ok=True)\n","    dir_list = glob('/content/data/라벨링데이터/*')\n","\n","    image_idx = 0\n","    annotation_idx = 0\n","\n","    images = [] # {'id':image_idx, 'file_name': '.png','width':d['Image_Width'], 'height':d['Image_Height']}\n","    annotations = [] # {'id':annotations_idx, 'image_id':image_idx, 'category_id':0,'bbox':(x,y,w,h), 'area':w*h, 'ignore':0,'iscrowd':0,'segmentation':[]}\n","    for idx, i in tqdm(enumerate(dir_list)): # directory\n","        dir_name = i.split('/')[-1]\n","        json_list = glob(os.path.join(i, '*')) # json파일\n","        if mode == 'train': ############################## train, valid 비율설정\n","            iter = json_list[:int(len(json_list)*0.8)]\n","        else:\n","            iter = json_list[int(len(json_list)*0.8):]\n","        for j in iter:\n","            with open(j, 'r', encoding='utf-8-sig') as jfile:\n","                d = json.load(jfile)\n","                image_name = d['Image_filename']\n","                image_num = image_name[-4:]\n","                if d['Image_Char_no'] > 500:\n","                    continue      \n","                image = plt.imread(i.replace('라벨링데이터','이미지데이터')+'/'+dir_name+image_num+'.png') # h, w, c\n","                h,w,c = image.shape\n","\n","                mini_y, maxi_y, mini_x, maxi_x = decide_min_max(d['Text_Coord'], h,w)\n","                \n","                result = image[mini_y:maxi_y, mini_x:maxi_x,:] ### ----------------- 글 주변만 자른 이미지 ----------------- ###\n","                h_, w_, c_ = result.shape\n","\n","                ### ----------------- 가운데를 자르기 전 빈 공간이 있는지 체크 ----------------- ###\n","                width_check = np.array([0]*w_)\n","                for k in d['Text_Coord']:\n","                    bbox = k['bbox']\n","                    width_check[bbox[0]-mini_x:bbox[0]-mini_x+bbox[2]] += 1\n","                \n","                if h_/w_ < 1.0:\n","                    ### ----------------- 빈 공간이 있으면 이미지 분할 ----------------- ###\n","                    cutting = decide_cutting_point(width_check, w_)\n","                    if cutting is None:\n","                        continue\n","                    \n","                    left_coord = []\n","                    right_coord = []\n","                    \n","                    for k in d['Text_Coord']:\n","                        bbox = k['bbox']\n","                        bbox_ = [bbox[0]-mini_x,bbox[1]-mini_y,bbox[2],bbox[3]] # 원래 bbox에서 여백제거한만큼 이동\n","                        if bbox_[0] >= cutting:\n","                            bbox_[0] -= cutting\n","                            right_coord.append(bbox_)\n","                        else:\n","                            left_coord.append(bbox_)\n","                    \n","                    image_left = result[:,:cutting,:]  # 가로로 길면 분할\n","                    image_right = result[:,cutting:,:]\n","                    \n","                    h_left, w_left, _ = image_left.shape\n","                    h_right, w_right, _ = image_right.shape\n","                    if 2 > h_left / w_left >= 1: # 왼쪽 이미지에 대해서 자른 후 세로가 길어야 저장\n","                        if h_left*w_left > 4000000: \n","                            image_left_ = cv2.resize(image_left, (w_left//2, h_left//2)) # image, w, h\n","                            images = save_iamge(mode, image_idx, image_left_, w_left//2, h_left//2)\n","                        else:\n","                            images = save_iamge(mode, image_idx, image_left, w_left, h_left)\n","                        annotations, annotation_idx = append_annotations(image_right,image_right_,left_coord,annotations,image_idx,annotation_idx,seg_option,None)\n","                        image_idx += 1\n","                    if 2 > h_right / w_right >= 1: # 오른쪽 이미지에 대해서 자른 후 세로가 길어야 저장\n","                        if h_right*w_right > 4000000:\n","                            image_right_ = cv2.resize(image_right, (w_right//2, h_right//2)) # w, h\n","                            images = save_iamge(mode, image_idx, image_right_, w_right//2, h_right//2)\n","                        else:\n","                            plt.imsave(f'/content/data/{mode}/{image_idx:05d}.png', image_right)\n","                            images = save_iamge(mode, image_idx, image_left, w_left, h_left)\n","                        annotations, annotation_idx = append_annotations(image_right,image_right_,right_coord,annotations,image_idx,annotation_idx,seg_option,None)\n","                        image_idx += 1\n","                else: # 세로가 길면\n","                    if h_/w_ > 2 or d['Image_Char_no'] > 250:\n","                        continue\n","                    if h_*w_ > 4000000: ######################################## 이미지\n","                        result_ = cv2.resize(result, (w_//2, h_//2))\n","                        images = save_iamge(mode, image_idx, result_, w_//2, h_//2)\n","                    else:\n","                        images = save_iamge(mode, image_idx, result, w_left, h_left)\n","                    annotations, annotation_idx = append_annotations(result,result_,right_coord,annotations,image_idx,annotation_idx,seg_option,(mini_x,mini_y))\n","                    image_idx += 1\n","    return images, annotations"],"metadata":{"id":"rd7yadZ78t-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_json(images, annotations, mode='train'):\n","    coco_dict = dict(\n","        info= dict(\n","            year=2021, \n","            version=\"1.0\", \n","            description=\"OCR\", \n","            contributor=\"\", \n","            url=None, \n","            date_created=None\n","        ), # year, version, description, contributor, url, date_created\n","        licenses=dict(\n","            id=0,\n","            name='CC BY 4.0',\n","            url=''\n","        ), # id, name, url\n","        images=list(), # id, file_name, height, width\n","        annotations=list(), # id, image_id, category_id, bbox, area, iscrowd\n","        categories = [\n","            dict(id=0,\n","                name='word')\n","        ] # id, name, supercategory\n","    )\n","    coco_dict['images'] = images\n","    coco_dict['annotations'] = annotations\n","    coco_dict['categories'] = [{'id':0, 'name':'word','super_category':None}]\n","    with open(f'/content/data/{mode}.json', 'w', encoding='utf-8') as jfile:\n","        json.dump(coco_dict, jfile)"],"metadata":{"id":"FCzmlq24TFu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, annotations = make_dataset('train', seg_option=False, just_image=False)\n","save_json(images, annotations,'train')\n","del images, annotations\n","images, annotations = make_dataset('valid', seg_option=False, just_image=False)\n","save_json(images, annotations,'valid')"],"metadata":{"id":"2CLpXrS01z_z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 전처리 데이터 저장"],"metadata":{"id":"zPdQuYlT69_Q"}},{"cell_type":"code","source":["%cd /content/data\n","!zip -r /content/drive/MyDrive/input/valid.zip ./valid\n","!zip -r /content/drive/MyDrive/input/train.zip ./train\n","!cp /content/data/valid.json /content/drive/MyDrive/input/valid.json\n","!cp /content/data/train.json /content/drive/MyDrive/input/train.json"],"metadata":{"id":"fcVXxkTZ0XNp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 정상인지 확인"],"metadata":{"id":"y65TcPwsFUos"}},{"cell_type":"code","source":["mode = 'train'\n","# with open(f'/content/drive/MyDrive/detection/{mode}.json','r', encoding='utf-8') as f:\n","#     d = json.load(f)\n","with open(f'/content/data/{mode}.json','r',encoding='utf-8') as f:\n","    d = json.load(f)\n","for k in range(30):\n","    image_sample = d['images'][k]\n","\n","    ann_sample = []\n","    for i in d['annotations']:\n","        if i['image_id'] == image_sample['id']:\n","            ann_sample.append(i)\n","    print(len(ann_sample))\n","    f_name = image_sample['file_name']\n","    img = plt.imread(f'/content/data/{mode}/{f_name}')\n","    # plt.imshow(img)\n","    # plt.show()\n","    fig, ax = plt.subplots(figsize=(12,12))\n","    \n","    ## segmentation\n","    # tmp = np.zeros((image_sample['height'], image_sample['width']))\n","    # for j in ann_sample:\n","    #     for m in range(0, len(j['segmentation'][0]), 2):\n","    #         tmp[j['segmentation'][0][m+1], j['segmentation'][0][m]] = 1\n","    # ax.imshow(tmp, cmap='gray')\n","    # plt.show()\n","\n","    ## bounding box\n","    ax.imshow(img)\n","    for j in ann_sample:\n","        x,y,w,h = j['bbox']\n","        rect = patches.Rectangle((x,y),w,h, linewidth=3, edgecolor='r', facecolor='none')\n","        ax.add_patch(rect)\n","    plt.show()\n"],"metadata":{"id":"G1hy8US7FuC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnt = 0\n","for i in range(len(d['annotations'])):\n","    if len(d['annotations'][i]['segmentation'][0]) <= 4:\n","        print(d['annotations'][i])\n","        image_id = d['annotations'][i]['image_id']\n","        img = plt.imread(f'/content/data/{mode}/{image_id:05d}.png')\n","        # fig, ax = plt.subplots(figsize=(12,12))\n","        \n","        ax.imshow(img)\n","        for j in d['annotations']:\n","            x,y,w,h = j['bbox']\n","            \n","            if j['image_id'] == image_id and len(j['segmentation'][0])<=4:\n","                print(j['segmentation'][0])\n","                # rect = patches.Rectangle((x,y),w,h, linewidth=3, edgecolor='r', facecolor='none')\n","                # ax.add_patch(rect)\n","                cnt += 1\n","                bbox = img[y:y+h, x:x+w, :]\n","                plt.imshow(bbox)\n","                plt.show()\n","        # plt.show()\n","\n","cnt # 348개의 글자가 거의 사라짐 - mean이 문제일수도 -> 1.0 mean으로 바꾸니 3개로 줄엇다 -> mean 값으로 설정하면 검은색이 큰 경우에 \n","# 4개 이하 1223개 -> 맥스값의 절반은 어떨까?"],"metadata":{"id":"kfDeO3hJS8lv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MMDetection 학습"],"metadata":{"id":"VLCs3Z_kNoAf"}},{"cell_type":"code","source":["del images, annotations"],"metadata":{"id":"nciG4vznCaFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCUHtjDcqaXj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639650694489,"user_tz":-540,"elapsed":534,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"c3235e96-286f-4632-fac7-c1594715f4bd"},"source":["%cd /content/Swin-Transformer-Object-Detection/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Swin-Transformer-Object-Detection\n"]}]},{"cell_type":"code","metadata":{"id":"CtGoRhZdqdWC"},"source":["import sys\n","from mmcv import Config\n","from mmcv.runner import load_checkpoint\n","from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector, set_random_seed, init_detector\n","from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n","from mmdet.utils import collect_env, get_root_logger\n","\n","import torch\n","import time\n","import json\n","\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTN1euRUqevY"},"source":["classes = (\n","    \"word\",\n",")\n","CUR_PATH = os.getcwd()\n","CFG_PATH = \"/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/configs/cascade_rcnn/cascade_rcnn_swin_tiny_fpn_1x_coco.py\" # cascade_rcnn_swin_tiny_fpn_1x_coco.py / cascade_rcnn_r101_fpn_20e_coco.py\n","# CFG_PATH = \"/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/configs/swin/cascade_mask_rcnn_swin_base_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py\"\n","# CFG_PATH = \"/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py\"\n","PREFIX = \"/content/data/image\"\n","WORK_DIR = \"/content/drive/MyDrive/Colab Notebooks/Computer_Vision/work_dir\"\n","# CHK_PATH = \"/content/drive/MyDrive/Colab Notebooks/lesion_obd/cascade_mask_rcnn_swin_small_patch4_window7.pth\"\n","# config file 들고오기\n","cfg = Config.fromfile(CFG_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0A5Paze8YV2"},"source":["for i in cfg:\n","    print(i, '*'*40)\n","    print(cfg[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60YgWlBetesq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639719256909,"user_tz":-540,"elapsed":20253,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"ac6dd6a3-ace6-4d42-d421-701a2ac594f5"},"source":["\n","cfg.data.train.classes = classes\n","cfg.data.train.img_prefix = \"/content/data/train\"\n","cfg.data.train.ann_file = '/content/data/train.json'\n","\n","cfg.data.val.classes = classes\n","cfg.data.val.img_prefix = \"/content/data/valid\"\n","cfg.data.val.ann_file = '/content/data/valid.json'\n","\n","cfg.data.samples_per_gpu = 2\n","cfg.data.workers_per_gpu = 4\n","\n","cfg.seed = 42\n","cfg.gpu_ids = [0]\n","\n","distributed = False\n","cfg.model.backbone = {'type': 'SwinTransformer', 'embed_dim': 128, 'depths': [2, 2, 18, 2], 'num_heads': [4, 8, 16, 32], 'window_size': 12, 'mlp_ratio': 4.0, 'qkv_bias': True, 'qk_scale': None, 'drop_rate': 0.0, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.2, 'ape': False, 'patch_norm': True, 'out_indices': (0, 1, 2, 3), 'use_checkpoint': False}\n","cfg.model.neck = {'type': 'FPN', 'in_channels': [128, 256, 512, 1024], 'out_channels': 256, 'num_outs': 5}\n","\n","cfg.work_dir = WORK_DIR\n","cfg.runner.max_epochs = 20\n","cfg.rtotal_epochs = 20\n","cfg.optimizer = dict(type='Adam', lr=0.0001, weight_decay=0.0001)\n","\n","cfg.lr_config = dict(\n","    policy='CosineAnnealing', # The policy of scheduler, also support CosineAnnealing, Cyclic, etc. Refer to details of supported LrUpdater from https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py#L9.\n","    by_epoch=False,\n","    warmup='linear', # The warmup policy, also support `exp` and `constant`.\n","    warmup_iters=1000, # The number of iterations for warmup\n","    warmup_ratio=0.001, # The ratio of the starting learning rate used for warmup\n","    min_lr=1e-07)\n","\n","cfg.log_config.interval = 600\n","cfg.checkpoint_config.interval = 1\n","cfg.log_config = {'hooks': [{'type': 'TextLoggerHook'}], 'interval': 600}\n","\n","# cfg.resume_from = \n","\n","# cfg.load_from = '/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/pth/swin_base_patch4_window12_384.pth'\n","# cfg.load_from = '/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/pth/cascade_mask_rcnn_swin_base_patch4_window7.pth'\n","# cfg.load_from = '/content/drive/MyDrive/Colab Notebooks/Computer_Vision/work_dir/87.3_200_under.pth'\n","# cfg.optimizer_config.use_fp16 = False\n","# cfg.model.pretrained = None\n","# cfg.fp16 = None\n","model = build_detector(cfg.model)\n","\n","datasets = [build_dataset(cfg.data.train)]\n","model.CLASSES = datasets[0].CLASSES"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=14.95s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"code","source":["train_detector(model, datasets[0], cfg, distributed=distributed, validate=True)"],"metadata":{"id":"nT67pDcIJUu0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"DfV59anJpmR9"}},{"cell_type":"code","source":["import mmcv\n","from mmcv import Config\n","from mmdet.datasets import (build_dataloader, build_dataset,\n","                            replace_ImageToTensor)\n","from mmdet.models import build_detector\n","from mmdet.apis import single_gpu_test\n","from mmcv.runner import load_checkpoint\n","import os\n","from mmcv.parallel import MMDataParallel\n","import pandas as pd\n","from pandas import DataFrame\n","from pycocotools.coco import COCO\n","import numpy as np"],"metadata":{"id":"gpR_SkKWqZmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bITp82s2BKS5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639722867927,"user_tz":-540,"elapsed":541563,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"ec297b00-b264-49cf-c3ee-dadcc82dce01"},"source":["cfg.data.test.classes = classes\n","cfg.data.test.img_prefix = '/content/data/valid'\n","cfg.data.test.ann_file = '/content/data/valid.json'\n","\n","dataset = build_dataset(cfg.data.test)\n","data_loader = build_dataloader(\n","        dataset,\n","        samples_per_gpu=1,\n","        workers_per_gpu=cfg.data.workers_per_gpu,\n","        dist=False,\n","        shuffle=False)\n","model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n","\n","checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Computer_Vision/work_dir/epoch_7.pth'\n","checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n","\n","model.CLASSES = dataset.CLASSES\n","model = MMDataParallel(model.cuda(), device_ids=[0])\n","\n","output = single_gpu_test(model,data_loader, show_score_thr=0.05)\n","\n","predictio_strings = []\n","file_names = []\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=5.99s)\n","creating index...\n","index created!\n","load checkpoint from local path: /content/drive/MyDrive/Colab Notebooks/Computer_Vision/work_dir/epoch_7.pth\n","[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 3521/3521, 6.7 task/s, elapsed: 529s, ETA:     0s"]}]},{"cell_type":"code","source":["img_ = plt.imread(sorted(glob('/content/data/valid/*'))[0]) # "],"metadata":{"id":"rv9Xsv8CsMbj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12,12))\n","ax.imshow(img_)\n","\n","for idx, i in enumerate(output[0][0]):\n","    # x,y,w,h,confi = i\n","    x,y,w,h,confi = i\n","    rect = patches.Rectangle((x,y),w-x,h-y, linewidth=3, edgecolor='r', facecolor='none')\n","    ax.add_patch(rect)\n","\n"],"metadata":{"id":"K_Bm6rQvsS41"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# single infernece\n","from mmdet.apis import init_detector, inference_detector\n","import mmcv\n","\n","# Specify the path to model config and checkpoint file\n","config_file = '/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/configs/cascade_rcnn/cascade_rcnn_swin_tiny_fpn_1x_coco.py'\n","checkpoint_file = '/content/drive/MyDrive/Colab Notebooks/Computer_Vision/work_dir/epoch_7.pth'\n","\n","# build the model from a config file and a checkpoint file\n","model = init_detector(config_file, checkpoint_file, device='cuda:0')\n","\n","# test a single image and show the results\n","img = '/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/tests/0.png'  # or img = mmcv.imread(img), which will only load it once\n","result = inference_detector(model, img)\n","# visualize the results in a new window\n","print(result)\n","# or save the visualization results to image files\n","# model.show_result(img, result, out_file='result.jpg')\n"],"metadata":{"id":"7fJB7aJz0_0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = plt.imread('/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/detection/tests/0.png')\n","fig, ax = plt.subplots(figsize=(15,15))\n","ax.imshow(img)\n","file_idx = 0\n","for i in result[0]:\n","    x,y,w,h,con = i\n","    if con > 0.1:\n","        rect = patches.Rectangle((x,y),w-x,h-y, linewidth=2, edgecolor='r', facecolor='none')\n","        ax.add_patch(rect)\n","        print(x,y,w,h)\n","        pp = img[int(y):int(h), int(x):int(w), :]\n","        plt.imsave(f'/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/recognition/test/{file_idx:03d}.png', pp)\n","        file_idx += 1\n","        if file_idx == 2:\n","            break\n","    # break"],"metadata":{"id":"OKR8yvjJ6fbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8alI_JjEAofe"},"execution_count":null,"outputs":[]}]}