{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4315,"status":"ok","timestamp":1639002189434,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"},"user_tz":-540},"id":"DPfWJADezZ_-","outputId":"779acbc0-28f9-4583-fe3a-fd0580965e6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting colab_ssh\n","  Downloading colab_ssh-0.3.27-py3-none-any.whl (26 kB)\n","Installing collected packages: colab-ssh\n","Successfully installed colab-ssh-0.3.27\n"]}],"source":["!pip install colab_ssh --upgrade"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18303,"status":"ok","timestamp":1639002183063,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"},"user_tz":-540},"id":"BB6dD1SFzku_","outputId":"dda18cbd-a178-4cf0-b9c7-32c6029676da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jDTQUjTJCNq"},"outputs":[],"source":["!pip install -r '/content/drive/Othercomputers/내 컴퓨터/workspace/p4-fr-sorry-math-but-love-you/requirements.txt'\n","!pip install jamo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-nP0Wej_z-Bk"},"outputs":[],"source":["!unzip '/content/drive/MyDrive/input/ocr_ancient.zip' -d /content/data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3u8Y3SFj0HbK","executionInfo":{"status":"ok","timestamp":1639002953132,"user_tz":-540,"elapsed":422,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"outputs":[],"source":["# 오류데이터 수정\n","import os\n","from glob import glob\n","json_list = glob(os.path.join('/content/data/이미지데이터','*')) # derectory\n","for i in json_list:\n","    tmp_list = glob(os.path.join(i,'*'))\n","    for j in tmp_list: # image파일\n","\n","        if j.split('/')[-1][:-8] != i.split('/')[-1]:\n","            dir_name = i.split('/')[-1]\n","            img_number = j.split('/')[-1][-8:]\n","            os.rename(j, '/content/data/이미지데이터/'+dir_name+'/'+dir_name+img_number)"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"TrbR8SDy7PFY","executionInfo":{"status":"ok","timestamp":1639014526144,"user_tz":-540,"elapsed":291,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"outputs":[],"source":["import json, os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import cv2\n","from glob import glob\n","\n","from tqdm.auto import tqdm\n","from jamo import h2j, j2hcj"]},{"cell_type":"code","source":["!rm -rf /content/data/크랍이미지"],"metadata":{"id":"0tEF9JwNbvD0","executionInfo":{"status":"ok","timestamp":1639024553992,"user_tz":-540,"elapsed":31533,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":["## 글자 데이터 구축"],"metadata":{"id":"1qQ-9xBiDFRG"}},{"cell_type":"code","execution_count":120,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":48,"referenced_widgets":["ad67d1c93a9945638c4ae9ea94f2937e","395d0984a8814fa9971ad34f38a8e157","639bb6be0ac14d3b90c20862135d49d2","df962f69f57a4a388d83a8b12dd18cb4","bb0dea16f70243dd8457af6956ba111b","21717b62a90642dba7533991d962e1c9","9773f5502e2d4c21af108d3b0b2bfd49","b1a528c62783416ab1d4cd67b5f23a22"]},"id":"RfWHwFxd0gC7","executionInfo":{"status":"ok","timestamp":1639026880528,"user_tz":-540,"elapsed":2047076,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"73381cfd-0144-4d7b-d174-35526997de8c"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad67d1c93a9945638c4ae9ea94f2937e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=571), HTML(value='')))"]},"metadata":{}}],"source":["from jamo import h2j, j2hcj\n","\n","excep_word = ['풍', '날','젼','광','황','(']\n","vocab = set()\n","exception = set()\n","\n","w_list = []\n","h_list = []\n","\n","dir_list = glob(os.path.join('/content/data/라벨링데이터','*')) # derectory\n","os.makedirs('/content/data/크랍이미지', exist_ok=True)\n","chr_idx = 0\n","for i in tqdm(dir_list): # directory list\n","    dir_name = i.split('/')[-1]\n","    dir_path = '/'.join(i.split('/')[:-1])\n","    json_list = glob(os.path.join(i,'*'))\n","    for j in json_list: # json 파일 list\n","        with open(j, 'r', encoding='utf-8-sig') as jfile:\n","            d = json.load(jfile)\n","            image_num = d['Image_filename'][-4:]\n","            image_path = os.path.join(dir_path.replace('라벨링데이터', '이미지데이터'), dir_name, dir_name+image_num+'.png')\n","\n","            image_arr = np.fromfile(image_path, np.uint8)\n","            image = cv2.imdecode(image_arr, cv2.IMREAD_COLOR)\n","\n","            # print(image)\n","            # image = plt.imread(image_path)\n","            \n","            # fig, ax = plt.subplots(figsize=(12,12))\n","            # ax.imshow(image)\n","            \n","            for k in d['Text_Coord']:\n","                bbox = k['bbox']\n","                annotate = k['annotate']\n","                if bbox[2] < 56 or bbox[3] < 56:\n","                    continue\n","                pp = image[bbox[1]:bbox[1]+bbox[3],bbox[0]:bbox[0]+bbox[2],:] # 한글자 이미지\n","                rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3], linewidth=3, edgecolor='r', facecolor='none')\n","                # ax.add_patch(rect)\n","                \n","                try:\n","                    \n","                    if len(annotate) == 2:\n","                        extention = '.png'\n","                        result, encoded_img = cv2.imencode(extention, pp)\n","                        if result:\n","                            if annotate[0] in excep_word or annotate[1] in excep_word:\n","                                continue\n","                            with open(f'/content/data/크랍이미지/{dir_name}_{chr_idx:05d}_{annotate[0]}-{annotate[1]}-b_.png', 'wb') as f:\n","                                encoded_img.tofile(f)\n","                        vocab.add(annotate[0])\n","                        vocab.add(annotate[1])\n","                        vocab.add('b_')\n","                        chr_idx += 1\n","                        continue\n","                    elif len(annotate) == 3:\n","                        extention = '.png'\n","                        result, encoded_img = cv2.imencode(extention, pp)\n","                        if result:\n","                            if annotate[0] in excep_word or annotate[1] in excep_word or annotate[2] in excep_word:\n","                                continue\n","                            with open(f'/content/data/크랍이미지/{dir_name}_{chr_idx:05d}_{annotate[0]}-{annotate[1]}-{annotate[2]}_.png', 'wb') as f:\n","                                encoded_img.tofile(f) \n","                        vocab.add(annotate[0])\n","                        vocab.add(annotate[1])\n","                        vocab.add(annotate[2]+'_') \n","                        chr_idx += 1 \n","                        continue                     \n","                    elif len(annotate) >= 4:\n","                        continue\n","                    else:\n","                        pass\n","                    jamo_str = j2hcj(h2j(annotate))\n","                    if len(jamo_str) == 2:\n","                        extention = '.png'\n","                        result, encoded_img = cv2.imencode(extention, pp)\n","                        if result:\n","                            if jamo_str[0] in excep_word or jamo_str[1] in excep_word:\n","                                continue\n","                            with open(f'/content/data/크랍이미지/{dir_name}_{chr_idx:05d}_{jamo_str[0]}-{jamo_str[1]}-b_.png', 'wb') as f:\n","                                encoded_img.tofile(f)\n","                        vocab.add(jamo_str[0])\n","                        vocab.add(jamo_str[1])\n","                        vocab.add('b_')\n","                        chr_idx += 1                        \n","                    elif len(jamo_str) == 3:\n","                        extention = '.png'\n","                        result, encoded_img = cv2.imencode(extention, pp)\n","                        if result:\n","                            if jamo_str[0] in excep_word or jamo_str[1] in excep_word or jamo_str[2] in excep_word:\n","                                continue\n","                            with open(f'/content/data/크랍이미지/{dir_name}_{chr_idx:05d}_{jamo_str[0]}-{jamo_str[1]}-{jamo_str[2]}_.png', 'wb') as f:\n","                                encoded_img.tofile(f)\n","                        vocab.add(jamo_str[0])\n","                        vocab.add(jamo_str[1])\n","                        vocab.add(jamo_str[2]+'_') \n","                        chr_idx += 1  \n","                    else:\n","                        continue         \n","                    # plt.imsave(f'/content/data/크랍이미지/{dir_name}_{chr_idx:03d}_{jamo_str}.png', pp)\n","\n","                    # print('saved')\n","\n","                except:\n","                    exception.add(annotate)\n","                    # print('exception')\n","\n","                # print(jamo_str)\n","            # plt.show()\n","            # plt.imshow(pp)\n","            # plt.show()"]},{"cell_type":"code","source":["len(glob('/content/data/크랍이미지/*')) # 56 기준 : 5861 너무 적다. 32 기준 : 9861 너무 적다. / extend a, b 허용 56기준"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyvdY244TbzX","executionInfo":{"status":"ok","timestamp":1639016661499,"user_tz":-540,"elapsed":3165,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"86184e57-7108-48b2-ee3f-d0df30cea5af"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["744788"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["len(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVub5Wt-ZPrA","executionInfo":{"status":"ok","timestamp":1639023183709,"user_tz":-540,"elapsed":320,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"47907ea8-19d9-448c-85d6-3547228d34cc"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["192"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["list(vocab)"],"metadata":{"id":"5nTjciiTUls3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["real_vocab = vocab - set(ll)"],"metadata":{"id":"FnjJwE_vZJ1w","executionInfo":{"status":"ok","timestamp":1639023919141,"user_tz":-540,"elapsed":279,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["sorted(list(real_vocab))"],"metadata":{"id":"mfmNvzP7ZTDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/token.txt', 'w') as f:\n","    for i in sorted(list(real_vocab)):\n","        f.write(i+'\\n')"],"metadata":{"id":"jZao04WLdasS","executionInfo":{"status":"ok","timestamp":1639024457880,"user_tz":-540,"elapsed":279,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrWwlcDUdtuH","executionInfo":{"status":"ok","timestamp":1639024354826,"user_tz":-540,"elapsed":268,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"c2aee357-64f9-414a-aeb9-b47ed3a7f18d"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["for i in glob('/content/data/크랍이미지/*'):\n","    for j in ll:\n","        if j in i[-10:-4]:\n","            print(i)\n","            break"],"metadata":{"id":"RT0zVXrEcW4k","executionInfo":{"status":"ok","timestamp":1639026976129,"user_tz":-540,"elapsed":4147,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["cnt = 0\n","for i in real_vocab:\n","    if '^' in i:\n","        cnt += 1\n","cnt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLg3DgvZaIh4","executionInfo":{"status":"ok","timestamp":1639023802823,"user_tz":-540,"elapsed":374,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"926b802d-1ff8-4683-c3d1-b84d0d949326"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["76"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["len(real_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Oq-CQIJZM3r","executionInfo":{"status":"ok","timestamp":1639023176866,"user_tz":-540,"elapsed":285,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"13548afe-20fb-4ea4-e389-231ed0881c05"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["187"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["ll = ['풍', '날','젼','광','황','(']"],"metadata":{"id":"eEbpPHHsYq2H","executionInfo":{"status":"ok","timestamp":1639023780450,"user_tz":-540,"elapsed":283,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":6220,"status":"ok","timestamp":1639027061414,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"},"user_tz":-540},"id":"up_7AxHE0IkY","outputId":"cbcd5bac-90c4-4799-c598-89cc718c7020"},"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n","*{\n","\toutline:none;\n","}\n","code{\n","\tdisplay:inline-block;\n","\tpadding:5px 10px;\n","\tbackground: #444;\n","\tborder-radius: 4px;\n","\twhite-space: pre-wrap;\n","\tposition:relative;\n","\tcolor:white;\n","}\n",".copy-code-button{\n","\tfloat:right;\n","\tbackground:#333;\n","\tcolor:white;\n","\tborder: none;\n","\tmargin: 0 0 0 10px;\n","\tcursor: pointer;\n","}\n","p, li{\n","\tmax-width:700px;\n","}\n",".choices{\n","\tdisplay:flex;\n","\tflex: 1 0 auto;\n","}\n",".choice-section{\n","\tborder:solid 1px #555;\n","\tborder-radius: 4px;\n","\tmin-width:300px;\n","\tmargin: 10px 15px 0 0;\n","\tpadding: 0 15px 15px 15px ;\n","}\n",".button{\n","\tpadding: 10px 15px;\n","\tbackground:#333;\n","\tborder-radius: 4px;\n","\tborder:solid 1px #555;\n","\tcolor:white;\n","\tfont-weight:bold;\n","\tcursor:pointer;\n","}\n",".pill{\n","\tpadding:2px 4px;\n","\tborder-radius: 100px;\n","\tbackground-color:#e65858;\n","\tfont-size:12px;\n","\tfont-weight:bold;\n","\tmargin: 0 15px;\n","\tcolor:white;\n","}\n","</style>\n","<details class=\"choice-section\">\n","\t<summary style=\"cursor:pointer\">\n","\t\t<h3 style=\"display:inline-block;margin-top:15px\">⚙️ Client machine configuration<span class=\"pill\">Required</span></h3>\n","\t</summary>\n","\t<p>Don't worry, you only have to do this <b>once per client machine</b>.</p>\n","\t<ol>\n","\t\t<li>Download <a href=\"https://developers.cloudflare.com/argo-tunnel/getting-started/installation\">Cloudflared (Argo Tunnel)</a>, then copy the absolute path of the cloudflare binary</li>\n","\t\t<li>Now, you have to append the following to your SSH config file (usually under ~/.ssh/config), and make sure you replace the placeholder with the path you copied in Step 1:</li>\n","\t</ol>\n","\t<code>Host *.trycloudflare.com\n","\tHostName %h\n","\tUser root\n","\tPort 22\n","\tProxyCommand &ltPUT_THE_ABSOLUTE_CLOUDFLARE_PATH_HERE&gt access ssh --hostname %h\n","\t</code>\n","</details>\n","<div class=\"choices\">\n","\t<div class=\"choice-section\">\n","\t\t<h4>SSH Terminal</h4>\n","\t\t<p>To connect using your terminal, type this command:</p>\n","\t\t<code>ssh tag-flickr-lexmark-penetration.trycloudflare.com</code>\n","\t</div>\n","\t<div class=\"choice-section\">\n","\t\t<h4>VSCode Remote SSH</h4>\n","\t\t<p>You can also connect with VSCode Remote SSH (Ctrl+Shift+P and type \"Connect to Host...\"). Then, paste the following hostname in the opened command palette:</p>\n","\t\t<code>tag-flickr-lexmark-penetration.trycloudflare.com</code>\n","\t</div>\n","</div>\n","\n","<script>\n","// Copy any string\n","function fallbackCopyTextToClipboard(text) {\n","  var textArea = document.createElement(\"textarea\");\n","  textArea.value = text;\n","  \n","  // Avoid scrolling to bottom\n","  textArea.style.top = \"0\";\n","  textArea.style.left = \"0\";\n","  textArea.style.position = \"fixed\";\n","\n","  document.body.appendChild(textArea);\n","  textArea.focus();\n","  textArea.select();\n","\n","  try {\n","    var successful = document.execCommand('copy');\n","    var msg = successful ? 'successful' : 'unsuccessful';\n","    console.log('Fallback: Copying text command was ' + msg);\n","  } catch (err) {\n","    console.error('Fallback: Oops, unable to copy', err);\n","  }\n","\n","  document.body.removeChild(textArea);\n","}\n","\n","// Show the copy button with every code tag\n","document.querySelectorAll('code').forEach(function (codeBlock) {\n","\tconst codeToCopy= codeBlock.innerText;\n","\tvar pre = document.createElement('pre');\n","\tpre.innerText = codeToCopy;\n","    var button = document.createElement('button');\n","    button.className = 'copy-code-button';\n","    button.type = 'button';\n","    button.innerText = 'Copy';\n","\tbutton.onclick = function(){\n","\t\tfallbackCopyTextToClipboard(codeToCopy);\n","\t\tbutton.innerText = 'Copied'\n","\t\tsetTimeout(()=>{\n","\t\t\tbutton.innerText = 'Copy'\n","\t\t},2000)\n","\t}\n","\tcodeBlock.children = pre;\n","\tcodeBlock.prepend(button)\n","});\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}],"source":["from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","launch_ssh_cloudflared(password=\"rkd954115@\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDKwzjCK0JKA"},"outputs":[],"source":["while 1:\n","  a = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DT69XeD60JnM"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1638863824818,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"},"user_tz":-540},"id":"kkjjQfbz4RLw","outputId":"9c923ea9-dfbc-4c0a-e861-7dd41ba88873"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/recognition\n"]}],"source":["%cd '/content/drive/Othercomputers/내 컴퓨터/workspace/ocr_ancient_korean/recognition'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgbasODEJAzN"},"outputs":[],"source":["import warnings\n","from importlib import import_module\n","import wandb\n","\n","parser = {\n","    'config_file': './test.yaml'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3609,"status":"ok","timestamp":1638863500683,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"},"user_tz":-540},"id":"SjoNZZhq4FTl","outputId":"1e295e14-0f33-4014-eac4-2346e9d14b06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.28.1)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa5ppvwZJAzR"},"outputs":[],"source":["import os\n","import time\n","from tqdm import tqdm\n","import yaml\n","import shutil\n","import multiprocessing\n","import numpy as np\n","import torch\n","from torch import nn, optim\n","import wandb\n","from utils import (\n","    load_checkpoint,\n","    save_checkpoint,\n","    Flags,\n","    set_seed,\n","    get_optimizer,\n","    get_network,\n","    id_to_string\n",")\n","from data import get_train_transforms, get_valid_transforms, dataset_loader,\\\n","    START, PAD\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4MSleXeJAzT"},"outputs":[],"source":["def _train_one_epoch(\n","    data_loader,\n","    model,\n","    epoch_text,\n","    criterion,\n","    optimizer,\n","    lr_scheduler,\n","    max_grad_norm,\n","    device,\n","    scaler,\n","    tf_scheduler,\n","    is_logging: bool\n","):\n","    torch.set_grad_enabled(True)\n","    model.train()\n","\n","    losses = []\n","    grad_norms = []\n","    correct_symbols = 0\n","    total_symbols = 0\n","    wer = 0\n","    num_wer = 0\n","    sent_acc = 0\n","    num_sent_acc = 0\n","\n","    with tqdm(\n","        desc=f\"{epoch_text} Train\",\n","        total=len(data_loader.dataset),\n","        dynamic_ncols=True,\n","        leave=False,\n","    ) as pbar:\n","        for d in data_loader:\n","            input = d[\"image\"].to(device).float()\n","            tf_ratio = tf_scheduler.step()  # Teacher Forcing Scheduler\n","            curr_batch_size = len(input)\n","            expected = d[\"truth\"][\"encoded\"].to(device)\n","            expected[expected == -1] = data_loader.dataset.token_to_id[PAD]\n","\n","            output = model(input, expected, True, tf_ratio)  # [B, MAX_LEN, VOCAB_SIZE]\n","\n","            decoded_values = output.transpose(1, 2)  # [B, VOCAB_SIZE, MAX_LEN]\n","            _, sequence = torch.topk(decoded_values, k=1, dim=1)  # [B, 1, MAX_LEN]\n","            sequence = sequence.squeeze(1)  # [B, MAX_LEN]\n","\n","            loss = criterion(decoded_values, expected[:, 1:])  # [SOS] 이후부터\n","            optim_params = [\n","                p\n","                for param_group in optimizer.param_groups\n","                for p in param_group[\"params\"]\n","            ]\n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            grad_norm = nn.utils.clip_grad_norm_(optim_params, max_norm=max_grad_norm)\n","            grad_norms.append(grad_norm)\n","\n","            optimizer.step()\n","            losses.append(loss.item())\n","\n","            expected[expected == data_loader.dataset.token_to_id[PAD]] = -1\n","            expected_str = id_to_string(expected, data_loader, do_eval=1)\n","            sequence_str = id_to_string(sequence, data_loader, do_eval=1)\n","            wer += word_error_rate(sequence_str, expected_str)\n","            num_wer += 1\n","            sent_acc += sentence_acc(sequence_str, expected_str)\n","            num_sent_acc += 1\n","            correct_symbols += torch.sum(sequence == expected[:, 1:], dim=(0, 1)).item()\n","            total_symbols += torch.sum(expected[:, 1:] != -1, dim=(0, 1)).item()\n","\n","            pbar.update(curr_batch_size)\n","            lr_scheduler.step()\n","\n","            # Weight & Bias\n","            if is_logging:\n","                if isinstance(lr_scheduler.get_lr(), float) or isinstance(\n","                    lr_scheduler.get_lr(), int\n","                ):\n","                    wandb.log(\n","                        {\"learning_rate\": lr_scheduler.get_lr(), \"tf_ratio\": tf_ratio}\n","                    )\n","                else:\n","                    wandb.log(\n","                        {\"learning_rate\": lr_scheduler.get_lr()[0], \"tf_ratio\": tf_ratio}\n","                    )\n","\n","    expected = id_to_string(expected, data_loader)\n","    sequence = id_to_string(sequence, data_loader)\n","\n","    result = {\n","        \"loss\": np.mean(losses),\n","        \"correct_symbols\": correct_symbols,\n","        \"total_symbols\": total_symbols,\n","        \"wer\": wer,\n","        \"num_wer\": num_wer,\n","        \"sent_acc\": sent_acc,\n","        \"num_sent_acc\": num_sent_acc,\n","    }\n","\n","    try:\n","        result[\"grad_norm\"] = np.mean([tensor.cpu() for tensor in grad_norms])\n","    except:\n","        result[\"grad_norm\"] = np.mean(grad_norms)\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLKVBSyRJAzU"},"outputs":[],"source":["def _valid_one_epoch(data_loader, model, epoch_text, criterion, device):\n","    model.eval()\n","\n","    losses = []\n","    correct_symbols = 0\n","    total_symbols = 0\n","    wer = 0\n","    num_wer = 0\n","    sent_acc = 0\n","    num_sent_acc = 0\n","\n","    NO_TEACHER_FORCING = 0.0\n","\n","    with torch.no_grad():\n","        with tqdm(\n","            desc=f\"{epoch_text} Validation\",\n","            total=len(data_loader.dataset),\n","            dynamic_ncols=True,\n","            leave=False,\n","        ) as pbar:\n","            for d in data_loader:\n","                input = d[\"image\"].to(device).float()\n","\n","                curr_batch_size = len(input)\n","                expected = d[\"truth\"][\"encoded\"].to(device)\n","\n","                expected[expected == -1] = data_loader.dataset.token_to_id[PAD]\n","                output = model(input, expected, False, NO_TEACHER_FORCING)\n","\n","                decoded_values = output.transpose(1, 2)  # [B, VOCAB_SIZE, MAX_LEN]\n","                _, sequence = torch.topk(\n","                    decoded_values, 1, dim=1\n","                )  # sequence: [B, 1, MAX_LEN]\n","                sequence = sequence.squeeze(1)  # [B, MAX_LEN], 각 샘플에 대해 시퀀스가 생성 상태\n","\n","                loss = criterion(decoded_values, expected[:, 1:])\n","                losses.append(loss.item())\n","\n","                expected[expected == data_loader.dataset.token_to_id[PAD]] = -1\n","                expected_str = id_to_string(expected, data_loader, do_eval=1)\n","                sequence_str = id_to_string(sequence, data_loader, do_eval=1)\n","                wer += word_error_rate(sequence_str, expected_str)\n","                num_wer += 1\n","                sent_acc += sentence_acc(sequence_str, expected_str)\n","                num_sent_acc += 1\n","                correct_symbols += torch.sum(\n","                    sequence == expected[:, 1:], dim=(0, 1)\n","                ).item()\n","                total_symbols += torch.sum(expected[:, 1:] != -1, dim=(0, 1)).item()\n","\n","                pbar.update(curr_batch_size)\n","\n","    expected = id_to_string(expected, data_loader)\n","    sequence = id_to_string(sequence, data_loader)\n","\n","    result = {\n","        \"loss\": np.mean(losses),\n","        \"correct_symbols\": correct_symbols,\n","        \"total_symbols\": total_symbols,\n","        \"wer\": wer,\n","        \"num_wer\": num_wer,\n","        \"sent_acc\": sent_acc,\n","        \"num_sent_acc\": num_sent_acc,\n","    }\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Uz8InwCJAzU"},"outputs":[],"source":["def main(parser):\n","    config_file = parser.config_file\n","    options = Flags(config_file).get() # config to namedtuple\n","    is_logging = True if parser.project_name is not None else False\n","\n","    set_seed(seed=options.seed)\n","\n","    is_cuda = torch.cuda.is_available()\n","    hardware = \"cuda\" if is_cuda else \"cpu\"\n","    device = torch.device(hardware)\n","    print(\"--------------------------------\")\n","    print(\"Running {} on device {}\\n\".format(options.network, device))\n","\n","    # Print system environments\n","    print_system_envs()\n","\n","    # Load checkpoint and print result\n","    checkpoint = (\n","        load_checkpoint(options.checkpoint, cuda=is_cuda)\n","        if options.checkpoint != \"\"\n","        else default_checkpoint\n","    )\n","\n","    model_checkpoint = checkpoint[\"model\"]\n","    if model_checkpoint:\n","        print(\n","            \"[+] Checkpoint\\n\",\n","            \"Resuming from epoch : {}\\n\".format(checkpoint[\"epoch\"]),\n","            \"Train Symbol Accuracy : {:.5f}\\n\".format(\n","                checkpoint[\"train_symbol_accuracy\"][-1]\n","            ),\n","            \"Train Sentence Accuracy : {:.5f}\\n\".format(\n","                checkpoint[\"train_sentence_accuracy\"][-1]\n","            ),\n","            \"Train WER : {:.5f}\\n\".format(checkpoint[\"train_wer\"][-1]),\n","            \"Train Loss : {:.5f}\\n\".format(checkpoint[\"train_losses\"][-1]),\n","            \"Validation Symbol Accuracy : {:.5f}\\n\".format(\n","                checkpoint[\"validation_symbol_accuracy\"][-1]\n","            ),\n","            \"Validation Sentence Accuracy : {:.5f}\\n\".format(\n","                checkpoint[\"validation_sentence_accuracy\"][-1]\n","            ),\n","            \"Validation WER : {:.5f}\\n\".format(checkpoint[\"validation_wer\"][-1]),\n","            \"Validation Loss : {:.5f}\\n\".format(checkpoint[\"validation_losses\"][-1]),\n","        )\n","\n","    (\n","        train_data_loader,\n","        validation_data_loader,\n","        train_dataset,\n","        valid_dataset,\n","    ) = dataset_loader(\n","        options,\n","        train_transform=get_train_transforms(\n","            options.input_size.height, options.input_size.width\n","        ),\n","        valid_transform=get_valid_transforms(\n","            options.input_size.height, options.input_size.width\n","        ),\n","        fold=options.data.fold,\n","    )\n","    print(\n","        \"[+] Data\\n\",\n","        \"The number of train samples : {}\\n\".format(len(train_dataset)),\n","        \"The number of validation samples : {}\\n\".format(len(valid_dataset)),\n","        \"The number of classes : {}\\n\".format(len(train_dataset.token_to_id)),\n","    )\n","\n","    # define model\n","    model = get_network(\n","        options.network,\n","        options,\n","        model_checkpoint,\n","        device,\n","        train_dataset,\n","    )\n","    model.train()\n","\n","    # define loss\n","    criterion = model.criterion.to(device)\n","\n","    # define optimizer\n","    enc_params_to_optimise = [\n","        param for param in model.encoder.parameters() if param.requires_grad\n","    ]\n","    dec_params_to_optimise = [\n","        param for param in model.decoder.parameters() if param.requires_grad\n","    ]\n","    params_to_optimise = [*enc_params_to_optimise, *dec_params_to_optimise]\n","    print(\n","        \"[+] Network\\n\",\n","        \"Type: {}\\n\".format(options.network),\n","        \"Encoder parameters: {}\\n\".format(\n","            sum(p.numel() for p in enc_params_to_optimise),\n","        ),\n","        \"Decoder parameters: {} \\n\".format(\n","            sum(p.numel() for p in dec_params_to_optimise),\n","        ),\n","    )\n","\n","    # Get optimizer and optimizer\n","    if options.scheduler.scheduler == \"CustomCosine\":\n","        optimizer = get_optimizer(\n","            options.optimizer.optimizer,\n","            params_to_optimise,\n","            lr=0,\n","            weight_decay=options.optimizer.weight_decay,\n","        )\n","        optimizer_state = checkpoint.get(\"optimizer\")\n","        if optimizer_state:\n","            optimizer.load_state_dict(optimizer_state)\n","\n","        # Custom Cosine Annealing 파라미터 명세 볼 만한 곳: https://bit.ly/2SGDhxO\n","        # T_0: 한 주기에 대한 스텝 수\n","        # T_mult: 주기 반복마다 주기 길이를 T_mult배로 바꿈\n","        # eta_max: warm-up을 통해 도달할 최대 LR\n","        # T_up: 한 주기 내에서 warm-up을 할 스텝 수\n","        # gamma: 주기 반복마다 주기 진폭을 gamma배로 바꿈\n","\n","        total_steps = len(train_data_loader) * options.num_epochs  # 전체 스텝 수\n","        t_0 = total_steps // 1  # 주기를 1로 설정\n","        t_up = int(t_0 * options.scheduler.warmup_ratio)  # 한 주기에서 10%의 스텝을 warm-up으로 사용\n","\n","        lr_scheduler = CustomCosineAnnealingWarmUpRestarts(\n","            optimizer,\n","            T_0=t_0,\n","            T_mult=1,\n","            eta_max=options.optimizer.lr,\n","            T_up=t_up,\n","            gamma=0.8,\n","        )\n","\n","        tf_scheduler = TeacherForcingScheduler(\n","            num_steps=total_steps,\n","            tf_max=options.teacher_forcing_ratio.tf_max,\n","            tf_min=options.teacher_forcing_ratio.tf_min,\n","        )\n","        print(\n","            \"[+] Teacher Forcing\\n\",\n","            \"Type: Arctan\\n\",\n","            f\"Steps: {total_steps}\\n\",\n","            f\"TF-MAX: {options.teacher_forcing_ratio.tf_max}\\n\",\n","            f\"TF-MIN: {options.teacher_forcing_ratio.tf_min}\\n\",\n","        )\n","\n","    else:\n","        optimizer = get_optimizer(\n","            options.optimizer.optimizer,\n","            params_to_optimise,\n","            lr=options.optimizer.lr,\n","            weight_decay=options.optimizer.weight_decay,\n","        )\n","        optimizer_state = checkpoint.get(\"optimizer\")\n","        if optimizer_state:\n","            optimizer.load_state_dict(optimizer_state)\n","        if options.scheduler.scheduler == \"ReduceLROnPlateau\":\n","            lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","                optimizer, patience=options.schduler.patience\n","            )\n","        elif options.scheduler.scheduler == \"StepLR\":\n","            lr_scheduler = optim.lr_scheduler.StepLR(\n","                optimizer,\n","                step_size=options.optimizer.lr_epochs,\n","                gamma=options.optimizer.lr_factor,\n","            )\n","        elif options.scheduler.scheduler == \"Cycle\":\n","            for param_group in optimizer.param_groups:\n","                param_group[\"initial_lr\"] = options.optimizer.lr\n","            cycle = len(train_data_loader) * options.num_epochs\n","            lr_scheduler = CircularLRBeta(\n","                optimizer, options.optimizer.lr, 10, 10, cycle, [0.95, 0.85]\n","            )\n","    if checkpoint[\"scheduler\"]:\n","        lr_scheduler.load_state_dict(checkpoint[\"scheduler\"])\n","\n","    # Log for W&B\n","    if is_logging:\n","        wandb.config.update(dict(options._asdict()))  # logging to W&B\n","\n","    if not os.path.exists(options.prefix):\n","        os.makedirs(options.prefix)\n","    log_file = open(os.path.join(options.prefix, \"log.txt\"), \"w\")\n","    shutil.copy(config_file, os.path.join(options.prefix, \"train_config.yaml\"))\n","    if options.print_epochs is None:\n","        options.print_epochs = options.num_epochs\n","    start_epoch = checkpoint[\"epoch\"]\n","    train_symbol_accuracy = checkpoint[\"train_symbol_accuracy\"]\n","    train_sentence_accuracy = checkpoint[\"train_sentence_accuracy\"]\n","    train_wer = checkpoint[\"train_wer\"]\n","    train_losses = checkpoint[\"train_losses\"]\n","    validation_symbol_accuracy = checkpoint[\"validation_symbol_accuracy\"]\n","    validation_sentence_accuracy = checkpoint[\"validation_sentence_accuracy\"]\n","    validation_wer = checkpoint[\"validation_wer\"]\n","    validation_losses = checkpoint[\"validation_losses\"]\n","    learning_rates = checkpoint[\"lr\"]\n","    grad_norms = checkpoint[\"grad_norm\"]\n","\n","    scaler = GradScaler()\n","\n","    best_score = 0.0\n","\n","    # Train\n","    for epoch in range(options.num_epochs):\n","        start_time = time.time()\n","\n","        epoch_text = \"[{current:>{pad}}/{end}] Epoch {epoch}\".format(\n","            current=epoch + 1,\n","            end=options.num_epochs,\n","            epoch=start_epoch + epoch + 1,\n","            pad=len(str(options.num_epochs)),\n","        )\n","\n","        train_result = _train_one_epoch(\n","            data_loader=train_data_loader,\n","            model=model,\n","            epoch_text=epoch_text,\n","            criterion=criterion,\n","            optimizer=optimizer,\n","            lr_scheduler=lr_scheduler,\n","            max_grad_norm=options.max_grad_norm,\n","            device=device,\n","            scaler=scaler,\n","            tf_scheduler=tf_scheduler,\n","            is_logging=is_logging\n","        )\n","\n","        train_losses.append(train_result[\"loss\"])\n","        grad_norms.append(train_result[\"grad_norm\"])\n","        train_epoch_symbol_accuracy = (\n","            train_result[\"correct_symbols\"] / train_result[\"total_symbols\"]\n","        )\n","        train_symbol_accuracy.append(train_epoch_symbol_accuracy)\n","        train_epoch_sentence_accuracy = (\n","            train_result[\"sent_acc\"] / train_result[\"num_sent_acc\"]\n","        )\n","\n","        train_sentence_accuracy.append(train_epoch_sentence_accuracy)\n","        train_epoch_wer = train_result[\"wer\"] / train_result[\"num_wer\"]\n","        train_wer.append(train_epoch_wer)\n","        train_epoch_score = final_metric(\n","            sentence_acc=train_epoch_sentence_accuracy, word_error_rate=train_epoch_wer\n","        )\n","        epoch_lr = lr_scheduler.get_lr()  # cycle\n","        validation_result = _valid_one_epoch(\n","            data_loader=validation_data_loader,\n","            model=model,\n","            epoch_text=epoch_text,\n","            criterion=criterion,\n","            device=device,\n","        )\n","\n","        validation_losses.append(validation_result[\"loss\"])\n","        validation_epoch_symbol_accuracy = (\n","            validation_result[\"correct_symbols\"] / validation_result[\"total_symbols\"]\n","        )\n","        validation_symbol_accuracy.append(validation_epoch_symbol_accuracy)\n","\n","        validation_epoch_sentence_accuracy = (\n","            validation_result[\"sent_acc\"] / validation_result[\"num_sent_acc\"]\n","        )\n","        validation_sentence_accuracy.append(validation_epoch_sentence_accuracy)\n","        validation_epoch_wer = validation_result[\"wer\"] / validation_result[\"num_wer\"]\n","        validation_wer.append(validation_epoch_wer)\n","        validation_epoch_score = final_metric(\n","            sentence_acc=validation_epoch_sentence_accuracy,\n","            word_error_rate=validation_epoch_wer,\n","        )\n","\n","        # Save checkpoint\n","        # make config\n","        with open(config_file, \"r\") as f:\n","            option_dict = yaml.safe_load(f)\n","\n","        if best_score < 0.9 * validation_epoch_sentence_accuracy + 0.1 * (\n","            1 - validation_epoch_wer\n","        ):\n","            save_checkpoint(\n","                {\n","                    \"epoch\": start_epoch + epoch + 1,\n","                    \"train_losses\": train_losses,\n","                    \"train_symbol_accuracy\": train_symbol_accuracy,\n","                    \"train_sentence_accuracy\": train_sentence_accuracy,\n","                    \"train_wer\": train_wer,\n","                    \"validation_losses\": validation_losses,\n","                    \"validation_symbol_accuracy\": validation_symbol_accuracy,\n","                    \"validation_sentence_accuracy\": validation_sentence_accuracy,\n","                    \"validation_wer\": validation_wer,\n","                    \"lr\": epoch_lr,\n","                    \"grad_norm\": grad_norms,\n","                    \"model\": model.state_dict(),\n","                    \"optimizer\": optimizer.state_dict(),\n","                    \"configs\": option_dict,\n","                    \"token_to_id\": train_data_loader.dataset.token_to_id,\n","                    \"id_to_token\": train_data_loader.dataset.id_to_token,\n","                    \"network\": options.network,\n","                    \"scheduler\": lr_scheduler.state_dict(),\n","                },\n","                prefix=options.prefix,\n","            )\n","            best_score = final_metric(\n","                sentence_acc=validation_epoch_sentence_accuracy,\n","                word_error_rate=validation_epoch_wer,\n","            )\n","            print(f\"best score: {best_score}\")\n","            print(\"model is saved\")\n","\n","        # Summary\n","        elapsed_time = time.time() - start_time\n","        elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n","        if epoch % options.print_epochs == 0 or epoch == options.num_epochs - 1:\n","            output_string = (\n","                \"{epoch_text}: \"\n","                \"Train Symbol Accuracy = {train_symbol_accuracy:.5f}, \"\n","                \"Train Sentence Accuracy = {train_sentence_accuracy:.5f}, \"\n","                \"Train WER = {train_wer:.5f}, \"\n","                \"Train Loss = {train_loss:.5f}, \"\n","                \"Validation Symbol Accuracy = {validation_symbol_accuracy:.5f}, \"\n","                \"Validation Sentence Accuracy = {validation_sentence_accuracy:.5f}, \"\n","                \"Validation WER = {validation_wer:.5f}, \"\n","                \"Validation Loss = {validation_loss:.5f}, \"\n","                \"lr = {lr} \"\n","                \"(time elapsed {time})\"\n","            ).format(\n","                epoch_text=epoch_text,\n","                train_symbol_accuracy=train_epoch_symbol_accuracy,\n","                train_sentence_accuracy=train_epoch_sentence_accuracy,\n","                train_wer=train_epoch_wer,\n","                train_loss=train_result[\"loss\"],\n","                validation_symbol_accuracy=validation_epoch_symbol_accuracy,\n","                validation_sentence_accuracy=validation_epoch_sentence_accuracy,\n","                validation_wer=validation_epoch_wer,\n","                validation_loss=validation_result[\"loss\"],\n","                lr=epoch_lr,\n","                time=elapsed_time,\n","            )\n","            print(output_string)\n","            log_file.write(output_string + \"\\n\")\n","\n","            if is_logging:\n","                write_wandb(\n","                    epoch=start_epoch + epoch + 1,\n","                    grad_norm=train_result[\"grad_norm\"],\n","                    train_loss=train_result[\"loss\"],\n","                    train_symbol_accuracy=train_epoch_symbol_accuracy,\n","                    train_sentence_accuracy=train_epoch_sentence_accuracy,\n","                    train_wer=train_epoch_wer,\n","                    train_score=train_epoch_score,\n","                    validation_loss=validation_result[\"loss\"],\n","                    validation_symbol_accuracy=validation_epoch_symbol_accuracy,\n","                    validation_sentence_accuracy=validation_epoch_sentence_accuracy,\n","                    validation_wer=validation_epoch_wer,\n","                    validation_score=validation_epoch_score,\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xST5_p7VGYTh"},"outputs":[],"source":["class Parser:\n","    config_file = \n","main()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"train.ipynb","provenance":[]},"interpreter":{"hash":"b424622832356a6c887192c2a2064810f646886fc95667f8686cbb29e5fd8ef5"},"kernelspec":{"display_name":"Python 3.7.12 64-bit ('ocr': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ad67d1c93a9945638c4ae9ea94f2937e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_395d0984a8814fa9971ad34f38a8e157","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_639bb6be0ac14d3b90c20862135d49d2","IPY_MODEL_df962f69f57a4a388d83a8b12dd18cb4"]}},"395d0984a8814fa9971ad34f38a8e157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"639bb6be0ac14d3b90c20862135d49d2":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bb0dea16f70243dd8457af6956ba111b","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":571,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":571,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_21717b62a90642dba7533991d962e1c9"}},"df962f69f57a4a388d83a8b12dd18cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9773f5502e2d4c21af108d3b0b2bfd49","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 571/571 [34:06&lt;00:00,  2.63s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1a528c62783416ab1d4cd67b5f23a22"}},"bb0dea16f70243dd8457af6956ba111b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"21717b62a90642dba7533991d962e1c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9773f5502e2d4c21af108d3b0b2bfd49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b1a528c62783416ab1d4cd67b5f23a22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}